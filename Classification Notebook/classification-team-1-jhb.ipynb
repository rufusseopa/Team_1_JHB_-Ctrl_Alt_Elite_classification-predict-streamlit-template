{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hE3z_ZXBfho"
   },
   "source": [
    "<hr>\n",
    "<h1><center>Climate Change Belief Analysis Competition</center></h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iod1ktDNBfhz"
   },
   "source": [
    "<a id='the_intro'></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wubGFt3d2Hx9"
   },
   "source": [
    "### Problem Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTMxcC_f2RRO"
   },
   "source": [
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "\n",
    "Providing an accurate and robust solution to this problem gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONUXTMViBfh7"
   },
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRp6-s4ZBfh9"
   },
   "source": [
    "The purpose of this project is to train a classification model to predict the sentiment of tweets related to climate change.\n",
    "\n",
    "The Machine Learning model chosen will be the one with the highest `Weighted F1-score `(the performance metric used to evaluate the models). \n",
    "\n",
    "Click [here](https://www.kaggle.com/c/climate-change-belief-analysis/overview) to view the competition page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d676wR1FBfht"
   },
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFeEOvg2Bfhw"
   },
   "source": [
    "1. [Introduction](#the_intro)\n",
    "\n",
    "1. [Data overview](#the_data)\n",
    " \n",
    "1. [Connecting to comet](#the_connection)\n",
    " \n",
    "1. [Importing the libraries](#the_libraries)\n",
    " \n",
    "1. [Loading the datasets](#the_load)\n",
    "\n",
    "1. [Inspecting the data](#inspecting)\n",
    " \n",
    "1. [Text preprocessing](#the_prep)\n",
    "\n",
    "1. [Exploratory data analysis](#the_analysis)\n",
    " \n",
    "1. [Feature engineering on text data](#the_features)\n",
    " \n",
    "1. [Modelling before resampling](#the_fit)\n",
    "\n",
    "1. [Hyperparameter tuning](#the_tune)\n",
    "\n",
    "1. [Modelling after resampling](#the_balancedfit)\n",
    "\n",
    "1. [Submissions to kaggle](#submission)\n",
    "\n",
    "1. [Evaluating the models](#the_eval)\n",
    " \n",
    "1. [Saving the best model](#the_saving)\n",
    "\n",
    "1. [Logging to comet](#the_logging)\n",
    "\n",
    "1. [Conclusion](#the_conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdrM5nXj2jg4"
   },
   "source": [
    "<a id='the_data'></a>\n",
    "## Data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx7gMxtS4Bam"
   },
   "source": [
    "The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected.\n",
    "\n",
    "The training and test datasets provided here is a subset of these 43943 tweets.\n",
    "\n",
    "The files to be downloaded are:\n",
    "* **Train.csv** - the dataset for training our model.\n",
    "* **Test.csv** - the dataset for testing our model .\n",
    "\n",
    "Variable definitions on the train dataset:\n",
    "\n",
    "`sentiment`: Sentiment of tweet\n",
    "\n",
    "`message`: Tweet body\n",
    "\n",
    "`tweetid`: Twitter unique ID\n",
    "\n",
    "Each tweet is labelled as one of the following sentiment classes:\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4k0BMQ1z_wgJ"
   },
   "source": [
    "<a id='the_connection'></a>\n",
    "## Connecting to comet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Bdr6an1_4dL"
   },
   "source": [
    "Comet is a platform that allows data scientists and developers to easily monitor, compare and optimize their machine learning models. \n",
    "More information about Comet can be found [here](https://techcrunch.com/2018/04/05/cometml-wants-to-do-for-machine-learning-what-github-did-for-code/#:~:text=Comet.ml%20allows%20data%20scientists,optimize%20their%20machine%20learning%20models.&text=The%20service%20provides%20you%20with,ML).  \n",
    "\n",
    "Firstly, `comet_ml` has to be installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BD0CcukAerr"
   },
   "outputs": [],
   "source": [
    "!pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWNcee8656VF"
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "\n",
    "#Setting up the API KEY\n",
    "experiment = Experiment(api_key= 'p0xSNBixchjaLhMutKMYVuJAq',project_name=\"classification_team_1_jhb\",workspace=\"crtshabangu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEj4oDes5bvg"
   },
   "source": [
    "<a id='the_libraries'></a>\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZrViDk65g4s"
   },
   "source": [
    "Before proceeding with importing the usual libraries, there are some natural language processing libraries that need to be installed: \n",
    "\n",
    "* `spacy`\n",
    "* `wordcloud`\n",
    "* `nltk`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylfS_Iu95gDn"
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install wordcloud\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAq8xhN212Sp"
   },
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud\n",
    "\n",
    "#modeling libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#text processing libraries\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import TreebankWordTokenizer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "#pickling\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOk8Taoe_lHW"
   },
   "source": [
    "<a id='the_load'></a>\n",
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v65gGRHwBfjN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkJkO-XoBGZk"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/climate-change-belief-analysis/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/climate-change-belief-analysis/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkEpisdUFJgM"
   },
   "source": [
    "<a id='inspecting'></a>\n",
    "## Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GV2A9wUEs0Q"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-M4JX1rtFaij"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8tHBW2bBfjj"
   },
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rKzQkyJBfjp"
   },
   "source": [
    "The training set has 15819 tweets.\n",
    "\n",
    "The testing set has 10546 tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5D7BzlfuK2of"
   },
   "source": [
    "For ease, the `tweetid` column is set to be the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgcc_N62K9XY"
   },
   "outputs": [],
   "source": [
    "train_data.set_index('tweetid', inplace=True)\n",
    "test_data.set_index('tweetid', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--UNlN93Bfjv"
   },
   "source": [
    "Checking for missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5Z-5KacBfjv"
   },
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02UP-StrBfjy"
   },
   "outputs": [],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEKJfJvoBfj2"
   },
   "source": [
    "Checking for empty strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGAXCy18Bfj3"
   },
   "outputs": [],
   "source": [
    "blanks = []  # start with an empty list\n",
    "\n",
    "for i,lb,tw in train_data.itertuples():  # iterate over the DataFrame\n",
    "    if type(tw)==str:                    # avoid NaN values\n",
    "        if tw.isspace():                 # test 'review' for whitespace\n",
    "            blanks.append(i)             # add matching index numbers to the list\n",
    "        \n",
    "print(len(blanks), 'blanks in train data: ', blanks)   # Checking for empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9jWz24eBfj6"
   },
   "outputs": [],
   "source": [
    "blanks = []  # start with an empty list\n",
    "\n",
    "for i, tw in test_data.iterrows():  # iterate over the DataFrame\n",
    "    if type(tw)==str:            # avoid NaN values\n",
    "        if tw.isspace():         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "        \n",
    "print(len(blanks), 'blanks in test data: ', blanks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KlU3DzdBfj_"
   },
   "source": [
    "Th data has no missing values, and no empty tweet strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2vLIzKtEoGY"
   },
   "source": [
    "<a id='the_prep'></a>\n",
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27Guc5gtGZ5J"
   },
   "source": [
    "In classification, the process of cleaning and standardization of text and making it noise-free is known as **text preprocessing**. This entails of:\n",
    "* Noise Removal.\n",
    "* Object Standardization.\n",
    "* Lexicon Normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu5vOrDZIx3e"
   },
   "source": [
    "### **Noise Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llPiRN8rI2yC"
   },
   "source": [
    "Any piece of information (text) that is not relevant in the data is considered as noise. The following constitutes as noise: stop words, urls, links, social media entities, punctuations or any industry-specific words. Noise is to be removed from our data as it is not required.\n",
    " \n",
    "Part of noise removal in this instance involves **Object Standardization**. \n",
    "\n",
    "Object Standardization involves making sense of, or removing words or phrases which are not present in any standard lexical dictionaries. These pieces are not recognized by search engines and models. Some examples include acronyms, hashtags with attached words, and colloquial slangs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1XpyxofFeMe"
   },
   "outputs": [],
   "source": [
    "#Converting every tweet to be lower case\n",
    "train_data['message'] = train_data['message'].str.lower()\n",
    "test_data['message'] = test_data['message'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVjcDHH3BfkI"
   },
   "source": [
    "Here, unexpected artifacts, urls, twitter handles and numbers in the tweets are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOEiakXrKHjB"
   },
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function takes in a text, and returns it cleaned of all noise \n",
    "    (such as  unexpected artifacts, urls, twitter handles and numbers).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@[\\w]*','',text)\n",
    "    text = re.sub(r'â€¦', '', text)\n",
    "    text = re.sub(r'…', '', text)\n",
    "    text = re.sub(r'â€™', \"'\", text)\n",
    "    text = re.sub(r'â€˜', \"'\", text)\n",
    "    text = re.sub(r'\\$q\\$', \"'\", text)\n",
    "    text = re.sub(r'&amp;', \"and\", text)\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    \n",
    "    words = text.split()  \n",
    "    \n",
    "    return( \" \".join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRm0EM7KSuyR"
   },
   "outputs": [],
   "source": [
    "train_data['message'] = train_data['message'].apply(cleaning)\n",
    "test_data['message'] = test_data['message'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9l7rh_XBfkQ"
   },
   "source": [
    "Python's `string` library is used to remove punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWH5BSGEBfkR"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    \n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2u4wND8BfkW"
   },
   "outputs": [],
   "source": [
    "train_data['message'] = train_data['message'].apply(remove_punctuation)\n",
    "test_data['message'] = test_data['message'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gI_q_vwwBfkY"
   },
   "source": [
    "It is noticed that the tweets contain 'rt', implying a retweet.\n",
    "\n",
    "Hence, 'rt', 'rts' and 'retweet' are added as stopwords, and all stopwords are now removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SUq5nFlgax_"
   },
   "outputs": [],
   "source": [
    "#Remove Stop words\n",
    "def stop(text):\n",
    "    \n",
    "    \"\"\"\" \n",
    "    Function takes in some text, adds the variants of 'retweets'\n",
    "    into the stopwords list, and then removes all stopwords.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    word = text.split()\n",
    "    #Remove stop words\n",
    "    stop_additional = ['rt','rts', 'retweet']\n",
    "    stop_word = set().union(stopwords.words('english'), stop_additional)\n",
    "    remove_stop = [w for w in word if w not in stop_word]\n",
    "    free_stop = \" \".join(remove_stop)\n",
    "    \n",
    "    return free_stop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKHayjizgm0J"
   },
   "outputs": [],
   "source": [
    "train_data['message'] = train_data['message'].apply(stop)\n",
    "test_data['message'] = test_data['message'].apply(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMofB282VO-I"
   },
   "source": [
    "### Lexicon Normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gC9KduwIXftk"
   },
   "source": [
    "Another type of textual noise to be removed include multiple representations exhibited by a single word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7nTxqSoX7QA"
   },
   "source": [
    "The common types of Lexicon Normalization:\n",
    "\n",
    "\n",
    "* **Stemming**:  Stemming is a rudimentary rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s”, etc) from a word.\n",
    "* **Lemmatization**: Lemmatization, on the other hand, is an organized, and step-by-step procedure of obtaining the root form of the word, by making use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations).\n",
    "\n",
    "In this case, lemmatization is chosen. In lemmatization, words like \"loving\", \"lovely\" and \"loved\" are normalized to their root-word \"love\".\n",
    "This process returns words present in our dictionary; unlike stemming which may return words that may not even exist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOj4Qs56Bfki"
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    \n",
    "    \"\"\"\" \n",
    "    Function takes in some text, and returns the lemmatized text.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lemma = WordNetLemmatizer()\n",
    "    new_text = \" \".join([lemma.lemmatize(lem) for lem in text.split()])\n",
    "    \n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37yssBh2Bfkl"
   },
   "outputs": [],
   "source": [
    "train_data['message'] = train_data['message'].apply(lemmatizer)\n",
    "test_data['message'] = test_data['message'].apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j78M2NOKYtKk"
   },
   "source": [
    "<a id='the_analysis'></a>\n",
    "## Explanatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PA7R-F4wNAeL"
   },
   "source": [
    "### Distribution of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txMcTtlJygvM"
   },
   "outputs": [],
   "source": [
    "# Separate the classes\n",
    "news = train_data[train_data['sentiment']==2]\n",
    "pro = train_data[train_data['sentiment']==1]\n",
    "neutral = train_data[train_data['sentiment']==0]\n",
    "anti = train_data[train_data['sentiment']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dxDJ4IykHPv"
   },
   "outputs": [],
   "source": [
    "# Get all possible labels\n",
    "labels = train_data['sentiment'].unique()\n",
    "heights = [len(pro),len(news),len(neutral),len(anti)]\n",
    "plt.bar(labels,heights,color='blue')\n",
    "plt.xticks(labels,['pro','news', 'neutral', 'anti'])\n",
    "plt.xlabel('sentiments')\n",
    "plt.ylabel(\"number of observations\")\n",
    "plt.title('Distribution of classes')\n",
    "experiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI3rqtr-NwuO"
   },
   "source": [
    "Many of the tweets are from people who believe in man-made climate change. Unresolved class imbalance can lead to the classifier been good at predicting the class(es) with the majority of the data points in the dataset. Whether class imbalance results in poor performance or not is something that will be tested. \n",
    "\n",
    "The exact percentages of these classes are now inspected using a pie chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_OfwEK4N_LF"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "train_data[\"sentiment\"].value_counts().plot.pie(labels=['Pro', 'News', 'Neutral', 'Anti'], \n",
    "                                                autopct='%.1f%%',\n",
    "                                                title = 'Pie chart showing percentage of class distribution',\n",
    "                                                colors = ['grey','lime','brown','blue'])\n",
    "experiment.log_figure(figure=plt,figure_name='Pie chart showing percentages of class distridution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nv2eL67jBfk-"
   },
   "source": [
    "More that 50% of the tweets belong to the `pro` class. Recall that the `pro` class represent tweets of people who believe in man-made climate change. This could be an indication that people are finally acknowledging this phenomenon, and more people are becoming aware of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25FQN9Z3Bfk_"
   },
   "source": [
    "### Length of tweets per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-SsTarCBflA"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(11,7))\n",
    "\n",
    "axs[0, 0].hist(pro.message.str.len(),bins=50,label='pro',color='grey')\n",
    "axs[0, 0].set_title('pro')\n",
    "\n",
    "axs[1, 0].set_title('news')\n",
    "axs[1, 0].hist(news.message.str.len(),bins=50,label='news',color='lime')\n",
    "\n",
    "axs[0, 1].set_title('neutral')\n",
    "axs[0, 1].hist(neutral.message.str.len(),bins=50,label='neutral',color='brown')\n",
    "\n",
    "axs[1, 1].set_title('anti')\n",
    "axs[1, 1].hist(anti.message.str.len(),bins=50,label='anti',color='blue')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='length of tweets', ylabel='number of tweets')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "experiment.log_figure(figure=plt,figure_name='histograms showing the count of length of tweets')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrfW63StBflD"
   },
   "source": [
    "It seems like the length for most tweets lie in the `20-120` range in all classes. \n",
    "\n",
    "**BETTER EXPLANATION HERE!!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLpeVkv7cKi0"
   },
   "source": [
    "### Wordclouds: Visualizing frequently used words in the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GInyxbbLBflE"
   },
   "source": [
    "A **word cloud** is a technique used in visualization to represent text data in such a way that the size of each word in the text indicate its significance or occurrances. Words that are largely displayed have a high frequency in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnOzLrAOcsXY"
   },
   "source": [
    "#### WordCloud 1: Top 50 Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbgi8m-Hb0ME"
   },
   "outputs": [],
   "source": [
    "all_words = ''.join([label for label in train_data['message']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHtJMi3Ic3tP"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 50 Words')\n",
    "experiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdFqZ9HY-oa9"
   },
   "source": [
    "This visual depicts the 50 most common words in the dataset. \n",
    "\n",
    "Words like \"climate change\", \"global warming\" and \"science\" are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbSMx0k_d25V"
   },
   "source": [
    "#### WordCloud2: Top 50 Words in \"Pro\" Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88o1dkVZdp9O"
   },
   "outputs": [],
   "source": [
    "pro_tweets = train_data[train_data['sentiment'] == 1]\n",
    "all_words = ''.join([label for label in pro_tweets['message']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "id": "NXOV6aAber8u"
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 50 Words in Pro Tweets')\n",
    "experiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in Pro Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkhyp0_KBflW"
   },
   "source": [
    "This visual depicts the 50 most common words among `pro` tweets.\n",
    "\n",
    "Words like \"change denier\", \"tackle climate\" and \"going die\" are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRUNcxU2e5st"
   },
   "source": [
    "#### WordCloud3: Top 50 Words in \"Anti\" Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzDdSSodew67"
   },
   "outputs": [],
   "source": [
    "anti_tweets = train_data[train_data['sentiment'] == -1]\n",
    "all_words = ''.join([label for label in anti_tweets['message']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4lhMfAKfE8_"
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 50 Words in Anti Tweets')\n",
    "experiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in Anti Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FuQ3Ds59wo1"
   },
   "source": [
    "This visual depicts the 50 most common words among `anti` tweets.\n",
    "\n",
    "Words like \"chinese\", \"man made\" and \"trump\" are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLri0ZLyfOdo"
   },
   "source": [
    "#### WordCloud4: Top 50 Words in \"Neutral\" Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZcW_avLfI-m"
   },
   "outputs": [],
   "source": [
    "neutral_tweets = train_data[train_data['sentiment'] == 0]\n",
    "all_words = ''.join([label for label in neutral_tweets['message']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwgaW7lxfgrq"
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 50 Words in Neutral Tweets')\n",
    "experiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in Neutral Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twUQ1Tu0Bflx"
   },
   "source": [
    "This visual depicts the 50 most common words among `neutral` tweets.\n",
    "\n",
    "Words like \"warming\", \"global\" and \"club penguin\" are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVQ_X9_hfuci"
   },
   "source": [
    "####  WordCloud5: Top 50 Words in \"News\" Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmSTvSHvfle9"
   },
   "outputs": [],
   "source": [
    "news_tweets = train_data[train_data['sentiment'] == 2]\n",
    "all_words = ''.join([label for label in news_tweets['message']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmoFdvshf0aV"
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Top 50 Words in News Tweets')\n",
    "experiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in News Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09V4izA9Bfl9"
   },
   "source": [
    "This visual depicts the 50 most common words among `news` tweets.\n",
    "\n",
    "Words like \"paris agreement\", \"scott pruitt\" and \"carbon dioxide\" are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Drgdxz7UY4d0"
   },
   "source": [
    "<a id='the_features'></a>\n",
    "## Feature engineering on text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTa9ldGFZZfD"
   },
   "source": [
    "Feature engineering on text data simply means extracting features from text using the following techniques:\n",
    "\n",
    "* **Bag of Words** <br>\n",
    "This extracts features from text and counts the frequency of words in a document (the simplest form). \n",
    "<br>\n",
    "*  **TF-IDF** <br>\n",
    "Tfidf combines **Term Frequency (TF)** and **Inverse Document Frequency** (IDF). It computes the term frequency-inverse document value for each word. TF is the raw count of a term in a document. IDF is an algorithm that reduces the weight for most common words and add more weight for words that are rare in a document. We compute these two as follows:\n",
    "  * TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "  * IDF(t) = log_e(Total number of documents / Number of documents with term t in it) \n",
    "  <br>\n",
    "\n",
    "* **Word2Vec** <br>\n",
    "This is a two layer neutral-net that processes text.\n",
    "\n",
    "This notebook makes use of the **TF-IDF** method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1acpfNcGBfl_"
   },
   "source": [
    "Firstly, the data has to be split into labels and features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feYZCCRoGpPE"
   },
   "source": [
    "### Obtaining X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "MOxLlwaPGoVT"
   },
   "outputs": [],
   "source": [
    "X = train_data['message']\n",
    "y = train_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is now split up into the training dataset and the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyZ0oz32BfmD"
   },
   "source": [
    "### Splitting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXC53bEzBfmF"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbj1_ukAbgBw"
   },
   "source": [
    "### Applying Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1Xc7b8Fbl6F"
   },
   "source": [
    "We now apply scikit-learn's `TfidfVectorizer` which does the following to our text data:\n",
    "\n",
    "*   It counts all the occurrences of the unique words and transforms the tweets to feature vectors\n",
    "*   A refinement on top of counting the words is to downscale the weight for words that occur in many tweets (such as \"the\") and are therefore less informative than those that occur only in a few tweets (such as \"climate\").\n",
    "*   This is achieved by simply dividing the number of occurrences of each word in the tweets by the total number of words in the tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CelvHzU0a_Ov"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bljkafltb9E-"
   },
   "source": [
    "Note the shape of `X_train_tfidf`, which indicates the number of features in the feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGddBsj_iZm2"
   },
   "source": [
    "<a id='the_fit'></a>\n",
    "## Modelling before resampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aaVuZbNBfmQ"
   },
   "source": [
    "**Models to Fit:**\n",
    "\n",
    "1. **Logistic Regression**\n",
    "   * Logistic Regression models the probability that `Y`(label) belongs to a certain category (or class). It uses the logistic       function to fit the model using the **maximum likelihood** method. It produces an `S-shaped` curve. This model         can be extended to Multi-class classification, where multiple logistic models can be combined using the          `one-vs-rest` approach.\n",
    "<br>   \n",
    "\n",
    "\n",
    "2. **Support Vector Machine**\n",
    "   *  In classification, an SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on the side of the gap on which they fall.\n",
    "   *  In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n",
    "<br> \n",
    "\n",
    " \n",
    "3. **K-Nearest Neighbors (K-NN)**\n",
    "   * K-NN is an easy and powerful machine learning algorithm. The algorithm works by assigning the majority class of the N-closest neighbors to the current data point. Hence, no training is required for the algorith; the only thing that needs to be done is choosing the value of `k` (i.e. the number of neighbors to consider) and choose the Euclidean distance function (`minkowski`) to calculate proximity.<br>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs7_xj2XjYGs"
   },
   "source": [
    "### Modelling with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqxZkPTbjBH2"
   },
   "source": [
    "Remember that only the training set has been vectorized into a full vocabulary. In order to perform an analysis on the test set, it has to be submitted to the same procedures. Hence, the `Pipeline` class is used. .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrV9Xy57BfmT"
   },
   "outputs": [],
   "source": [
    "def fit_evaluate_model(model, X_train, y_train):\n",
    "    \n",
    "    \"\"\" \n",
    "    Function takes a model to train as input, and returns the performance\n",
    "    of said model (in the form of various metrics). \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                         ('clf',model)])\n",
    "    \n",
    "    # Fit the model to the training set\n",
    "    text_clf.fit(X_train, y_train) \n",
    "    \n",
    "    # Obtain predictions on the training and validation set\n",
    "    y_pred = text_clf.predict(X_train)\n",
    "    y_pred_test=text_clf.predict(X_test)\n",
    "    \n",
    "    # Determining the performance of the model\n",
    "    accuracy = accuracy_score(y_train,y_pred)\n",
    "    precision = precision_score(y_train,y_pred,average='weighted')\n",
    "    recall = recall_score(y_train,y_pred,average='weighted')\n",
    "    f1 = f1_score(y_train,y_pred,average='weighted')\n",
    "    f1_test = f1_score(y_test,y_pred_test,average='weighted')\n",
    "    \n",
    "    # Create dictionary for metrics\n",
    "    performance = {\"accuracy\": accuracy,\"precision\":precision,\n",
    "                   \"recall\":recall,\"f1_score\":f1,\"f1_test_score\":f1_test}\n",
    "    \n",
    "    output = pd.DataFrame([performance])\n",
    "\n",
    " \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1RASFGYBfmX"
   },
   "source": [
    "#### Model 1 : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8WToKEIBfmX"
   },
   "outputs": [],
   "source": [
    "model1 = LogisticRegression(max_iter=10000)\n",
    "logistic_model = fit_evaluate_model(model1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAEIkcm6Bfmd"
   },
   "source": [
    "#### Model 2: Linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGcXHvpzBfme"
   },
   "outputs": [],
   "source": [
    "model2 = LinearSVC()\n",
    "linear_svc = fit_evaluate_model(model2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjR02EgmBfmi"
   },
   "source": [
    "#### Model 3 : Kernel SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQX4mAU8Bfmj"
   },
   "outputs": [],
   "source": [
    "model3 = SVC(kernel = 'rbf')\n",
    "kernel_svc = fit_evaluate_model(model3, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF9jHJrWAdNI"
   },
   "source": [
    "#### Model 4 : K-NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7y-dkyYtAdNJ"
   },
   "outputs": [],
   "source": [
    "model4 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "k_nn = fit_evaluate_model(model4,X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrDDVc1aBfmm"
   },
   "source": [
    "#### Assessing the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L70wP_7lBfmm"
   },
   "outputs": [],
   "source": [
    "assess = pd.concat([logistic_model, linear_svc, kernel_svc, k_nn])\n",
    "assess.index = ['Logistic Regression','Linear SVM Model','Kernel SVM Model', 'K-NN Model']\n",
    "assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0nmMES3Bfms"
   },
   "source": [
    "The imbalance in our data can also be seen in the accuracy being significantly higher than the f1 score across all the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models' performance can be improved through **hyperparametric tuning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='the_tune'></a>\n",
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7afCx1d8EIOf"
   },
   "source": [
    "A hyperparameter is a value that is set before the model is trained. Different models have different algorithms, and hence have different hyperparameters. \n",
    "<br>\n",
    "\n",
    "Firstly, the hyperparameters of the fitted models are inspected: <br>\n",
    "\n",
    "**Logistic Regression**<br>\n",
    "`C`: controls regularization (shrinkage). The smaller value of `C`, the greater the amount of shrinkage that takes place. <br>\n",
    "\n",
    "**Support Vector Classifier** <br>\n",
    "`C`: controls the penalty of the error term.<br>\n",
    "`gamma`: kernel coefficient. <br>\n",
    "(Support Vector Classifier has tons of hyperparameters, but only these two are focused on, for the sake of efficiency).\n",
    "\n",
    "**KNN**<br>\n",
    "`n_neighbors`: number of nearest neighbors.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Z4BH9S6EIOh"
   },
   "source": [
    "Hyperparameter Tuning/Optimization is the process of selecting a certain combination of hyperparameters that are optimal for our model.\n",
    "<br>\n",
    "\n",
    "There are many techiniques to tune the hyperparameters; this notebook uses the `GridSearch` method.<br>\n",
    "\n",
    "A **GridSearch** is an optimization process that finds the best hyperparameters. It is a trial-and-error method used to train the model of various combinations of the specified hyperparameters. The hyperparameters chosen are the ones that fully optimize the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TaqMggjYAdNP"
   },
   "outputs": [],
   "source": [
    "def tuned_model(model, parameters):\n",
    "    \n",
    "    \"\"\" \n",
    "    Function takes a model to train and parameters to optimize as input,\n",
    "    and returns the best parameters and best F1-Score of said model.\n",
    "    \n",
    "    \"\"\"\n",
    "    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                         ('clf',model)]) \n",
    "    \n",
    "    grid_search = GridSearchCV(estimator = text_clf,\n",
    "                               param_grid = parameters,\n",
    "                               scoring = 'f1_weighted',\n",
    "                               cv = 10,\n",
    "                               n_jobs = -1)\n",
    "    grid_search = grid_search.fit(X_train, y_train)\n",
    "    best_accuracy = grid_search.best_score_\n",
    "    best_parameters = grid_search.best_params_\n",
    "    print(\"Best f1-score: {:.2f}\".format(best_accuracy))\n",
    "    print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S5DsLoVAdNU"
   },
   "source": [
    "#### Model 1: Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hK0Zb6eAdNU"
   },
   "outputs": [],
   "source": [
    "parameters = [{'clf__C': [0.05], 'clf__penalty': ['l1'], 'clf__solver': ['liblinear'], 'clf__verbose':[1]},\n",
    "              {'clf__C': np.linspace(1,10,10)}] \n",
    "\n",
    "tuned_model(model1, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9s4au61AdNZ"
   },
   "source": [
    "#### Model 2: Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Son55ApAdNa"
   },
   "outputs": [],
   "source": [
    "parameters = [{'clf__C': np.linspace(1,10,10), 'clf__penalty': ['l1','l2']}]\n",
    "\n",
    "tuned_model(model2, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUR-bF95AdNd"
   },
   "source": [
    "#### Model 3: Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ac7r7SmAdNe"
   },
   "source": [
    "**The following lines of code took hours to load:**\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "parameters = [{'clf__C': [1, 10, 100], 'clf__kernel': ['poly', 'rbf'],'clf__gamma': ['scale', 'auto']}] \n",
    "tuned_model(model3, parameters)\n",
    "```\n",
    "**And the output:**\n",
    "\n",
    "\n",
    "```\n",
    "Best f1-score: 0.73 \n",
    "Best Parameters: {'clf__C': 100, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4: K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'clf__n_neighbors': [5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "tuned_model(model4, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing the performance after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'F1-Score after tuning': [0.71, 0.70, 0.73, 0.63]}\n",
    "index=['Logistic Regression Tuned', 'Linear SVC Tuned', 'Kernel SVC Tuned', 'KNN Tuned']\n",
    "summary = pd.DataFrame(data = data, index=index)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAn2YTMQixnR"
   },
   "source": [
    "<a id='the_balancedfit'></a>\n",
    "## Modelling after resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puqyBU9Qmv2I"
   },
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPatdo-zjC_2"
   },
   "source": [
    "As mentioned before, the classes are imbalanced. The imbalance in the classes are fixed by `resampling`. Resampling consists of three techniques:\n",
    "\n",
    "\n",
    "*   **Upsampling** the minority class - increase the minority class by resampling from observations to match the number of observations in the majority class.\n",
    "\n",
    "\n",
    "*   **Downsampling** the majority class - reducing the number of observations in the majority class to match those of the minority class.\n",
    "\n",
    "\n",
    "*   **Synthetic data** - another type of upsampling method where the number of observations in the minority class are inflated, but by generating new observations which are very similar to (but not identical to) existing samples in the minority class. \n",
    "\n",
    "This notebook uses the upsampling and downsampling methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bam_Pf3qj8is"
   },
   "source": [
    "The model performance can possibly be improved by rebalancing our data. Before this is done, the current distribution of the classes are examined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEShW8cDBfmu"
   },
   "outputs": [],
   "source": [
    "# Separate the classes\n",
    "news = train_data[train_data['sentiment']==2]\n",
    "pro = train_data[train_data['sentiment']==1]\n",
    "neutral = train_data[train_data['sentiment']==0]\n",
    "anti = train_data[train_data['sentiment']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQo3IpyIBfmw"
   },
   "outputs": [],
   "source": [
    "# Get all possible labels\n",
    "labels = train_data['sentiment'].unique()\n",
    "heights = [len(pro),len(news),len(neutral),len(anti)]\n",
    "plt.bar(labels,heights,color='grey')\n",
    "plt.xticks(labels,['pro','news', 'neutral', 'anti'])\n",
    "plt.ylabel(\"# of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VizXAR3jkbxC"
   },
   "source": [
    "Now the resampling techniques are applied:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTVCnPiukmN0"
   },
   "source": [
    "#### Downsampling the majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kPJGZv0kwXf"
   },
   "source": [
    "Since the `pro` class has so many observations, its size can be reduced by taking a small random subset of observations to match the size of the `news` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7Jq3zOVkJac"
   },
   "outputs": [],
   "source": [
    "# Downsample majority\n",
    "pro_downsampled = resample(pro,\n",
    "                          replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=len(news)) # match number in minority class\n",
    "\n",
    "# Combine downsampled majority class with minority classes\n",
    "downsampled = pd.concat([pro_downsampled, anti, neutral, news])\n",
    "\n",
    "# Check new class counts\n",
    "downsampled['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bac7JA-YlPvY"
   },
   "outputs": [],
   "source": [
    "downsampled_heights = [len(downsampled[downsampled['sentiment']==1]),len(downsampled[downsampled['sentiment']==2]),\n",
    "                       len(downsampled[downsampled['sentiment']==0]),len(downsampled[downsampled['sentiment']==-1])]\n",
    "\n",
    "# Get all possible labels\n",
    "labels = train_data['sentiment'].unique()\n",
    "plt.bar(labels,heights,color='grey')\n",
    "plt.bar(labels,downsampled_heights,color='blue')\n",
    "plt.xticks(labels,['pro','news', 'neutral', 'anti'])\n",
    "plt.ylabel(\"number of observations\")\n",
    "plt.legend(['original','resampled'])\n",
    "experiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes after downsampling')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfErKGvklbxq"
   },
   "source": [
    "#### Upsampling the minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWTVOelSlefk"
   },
   "source": [
    " Here, random copies of observations in the `anti` and `neutral` classes are made until we match the size of the `news` class. Using this approach means that there will be more data; however the model will be prone to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36--x0lwk5ch"
   },
   "outputs": [],
   "source": [
    "# Upsample minority\n",
    "anti_upsampled = resample(anti,\n",
    "                          replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                          n_samples=len(news)) # match number in minority class\n",
    "\n",
    "# Combine upsampled anti class with majority classes\n",
    "up_sampled = pd.concat([pro_downsampled, anti_upsampled, neutral, news])\n",
    "\n",
    "# Check new class counts\n",
    "up_sampled['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNjbdqmkl1Jh"
   },
   "outputs": [],
   "source": [
    "# Upsample minority\n",
    "neutral_upsampled = resample(neutral,\n",
    "                          replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                          n_samples=len(news)) # match number in minority class\n",
    "\n",
    "# Combine upsampled neutral class with majority class\n",
    "final = pd.concat([pro_downsampled, anti_upsampled, neutral_upsampled, news])\n",
    "\n",
    "# Check new class counts\n",
    "final['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nwzB_fsl7G8"
   },
   "outputs": [],
   "source": [
    "upsampled_heights = [len(final[final['sentiment']==1]),len(final[final['sentiment']==2]),\n",
    "                     len(final[final['sentiment']==0]),len(final[final['sentiment']==-1])]\n",
    "\n",
    "# Get all possible labels\n",
    "labels = train_data['sentiment'].unique()\n",
    "plt.bar(labels,upsampled_heights,color='green')\n",
    "plt.bar(labels,heights,color='grey')\n",
    "plt.xticks(labels,['pro','news', 'neutral', 'anti'])\n",
    "plt.ylabel(\"number of observations\")\n",
    "plt.legend(['resampled','original'])\n",
    "experiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes after upsampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEabmov6mFXc"
   },
   "source": [
    "#### Visualizing the new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QRTplOYl_rv"
   },
   "outputs": [],
   "source": [
    "# Get all possible labels\n",
    "labels = train_data['sentiment'].unique()\n",
    "heights = [len(final[final['sentiment']==1]),len(final[final['sentiment']==2]),\n",
    "           len(final[final['sentiment']==0]),len(final[final['sentiment']==-1])]\n",
    "plt.bar(labels,heights,color='grey')\n",
    "plt.xticks(labels,['pro','news', 'neutral', 'anti'])\n",
    "plt.ylabel(\"number of observations\")\n",
    "experiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes after resampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pT4YrAa5mXm8"
   },
   "source": [
    "These are now evenly distributed observations that can now be thrown at any classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now split into labels and features, and the training set is split up into the training and validation datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNgjIFc0AdOH"
   },
   "source": [
    "### Splitting into the training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NR3HaIWzAdOI"
   },
   "outputs": [],
   "source": [
    "X = final['message'] \n",
    "y = final['sentiment'].values\n",
    "\n",
    "X_train_resampled, X_test, y_train_resampled, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RV5xdUbNm1Vw"
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVl9QlyiBfnH"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = fit_evaluate_model(model1, X_train_resampled, y_train_resampled) \n",
    "# Linear SVC model\n",
    "l_svc = fit_evaluate_model(model2, X_train_resampled, y_train_resampled)\n",
    "# Kernel SVM Model\n",
    "k_svc = fit_evaluate_model(model3, X_train_resampled, y_train_resampled)\n",
    "# K_Nearest Neighbours\n",
    "knn = fit_evaluate_model(model4, X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2I6SHDTBfnM"
   },
   "source": [
    "####  Assessing the performance on resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ix9wn9VWBfnM"
   },
   "outputs": [],
   "source": [
    "assess_resampled = pd.concat([logreg,l_svc,k_svc, knn])\n",
    "assess_resampled.index = ['Logistic Regression Resampled','Linear SVM Model Resampled',\n",
    "                          'Kernel SVM Model Resampled', 'K-NN Model Resampled']\n",
    "assess_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCr82XIUBfnO"
   },
   "source": [
    "An improvement of the models on the validation set can be seen since the data has been resampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='submission'></a>\n",
    "## Submissions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submissions are now made to Kaggle to see the performance of the models on the true testing dataset. These F1-scores are the ones that carry the most weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, filename, X, y):\n",
    "    \n",
    "    \"\"\"\" \n",
    "    Function takes a model, and X and y variables to train as input,\n",
    "    and returns a csv file of predictions (named as \"filename\") to \n",
    "    submit to Kaggle in order to obtain the true F1-score. \n",
    "    \n",
    "    \"\"\"\n",
    "    test_x = test_data['message']\n",
    "    \n",
    "    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                         ('clf',model)])\n",
    "    \n",
    "    # Fit the model to the training set\n",
    "    text_clf.fit(X, y) \n",
    "    \n",
    "    # Obtain predictions on the testing set\n",
    "    y_pred = text_clf.predict(test_x)\n",
    "    \n",
    "    # Save predictions in a new DataFrame\n",
    "    predictions = pd.DataFrame(y_pred, columns=['sentiment'], index = test_data.index)\n",
    "    predictions.reset_index(inplace=True)\n",
    "    \n",
    "    return predictions.to_csv('/kaggle/working/'+filename+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: F1 Score = 0.73364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(model1, 'LogReg', X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVC: F1 Score = 0.74834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(model2, 'LinearSVC', X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel SVM: F1 Score = 0.73577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(model3, 'KernelSVC', X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-NN: F1 Score = 0.64971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(model4, 'KNN', X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: F1 Score = 0.75225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(LogisticRegression(C=6.0, max_iter=10000), 'LogReg_Tuned', X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel SVM: F1 Score = 0.75651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(SVC(kernel='rbf', C=100, gamma='scale'), 'KernelSVC_Tuned', X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbours: F1 Score = 0.65259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(KNeighborsClassifier(leaf_size=20, n_neighbors=9), 'KNN_Tuned', X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with resampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: F1 Score = 0.65483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(model1, 'LogReg_Resampled', X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVC: F1 Score = 0.65659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(model2, 'LinearSVC_Resampled', X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel SVM: F1 Score = 0.69689"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(model3, 'KernelSVC_Resampled', X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbours: F1 Score = 0.49881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing(model4, 'KNN_Resampled', X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgYDMk7_Bfnf"
   },
   "source": [
    "<a id='the_eval'></a>\n",
    "## Evaluating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models built in this notebook are now evaluated according to the performance metric (The `F1-Score`) on the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [['Before Resampling', 'Before Resampling', 'Before Resampling', 'Before Resampling', \n",
    "           'Before Resampling Tuned', 'Before Resampling Tuned', 'Before Resampling Tuned',\n",
    "           'Before Resampling Tuned', 'After Resampling', 'After Resampling', 'After Resampling',\n",
    "           'After Resampling'],\n",
    "          ['Logistic Regression', 'Linear SVC', 'Kernel SVC', 'K-Nearest Neighbours',\n",
    "           'Logistic Regression', 'Linear SVC', 'Kernel SVC', 'K-Nearest Neighbours',\n",
    "           'Logistic Regression', 'Linear SVC', 'Kernel SVC', 'K-Nearest Neighbours']]\n",
    "\n",
    "tuples = list(zip(*arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36VtEk-mBfnf"
   },
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples(tuples, names=[' ', 'Model'])\n",
    "\n",
    "data = {'Train F1-Score': [0.8289, 0.9628, 0.9534, 0.7479, '--', '--', '--', '--',\n",
    "                           0.9083, 0.9797, 0.9879, 0.7531],\n",
    "        'Validation F1-Score': [0.7114, 0.7172, 0.7068, 0.6416, 0.7100,0.7000, 0.7300,\n",
    "                                0.6300, 0.7781, 0.8029, 0.8346, 0.6350],\n",
    "        'Test F1-Score': [0.7336, 0.7483, 0.7358, 0.6497, 0.7526, 0.7483, 0.7565, 0.6526,\n",
    "                         0.6548, 0.6566, 0.6969, 0.4988]}\n",
    "\n",
    "summary = pd.DataFrame(data = data, index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bePtZxk2Bfnl"
   },
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few observations:\n",
    "\n",
    "1. The models performed the best on the training set (understandably).\n",
    "2. The resampling done (especially upsampling the minority classes) caused our data to overfit; this can be seen by the very high F1-scores on the training set and a drastic decrease of the F1-score on the testing set. \n",
    "3. The K-Nearest Neighbors model consistently performed the worst. \n",
    "4. The Kernel SVM model consistently performed the best, indicating that the data is not linearly separable.\n",
    "5. Tuning the models definitely improved the performance of the model.\n",
    "6. The models that were tuned before resampling performed the best; the models built on the resampled data performed the worst.\n",
    "7. The highest `Test F1-score` = `0.75651`, indicating that **the best model is the Kernel SVM optimally tuned model before resampling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sR_0inDD1OcM"
   },
   "source": [
    "<a id='the_saving'></a>\n",
    "## Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHAwiWVytMeA"
   },
   "outputs": [],
   "source": [
    "model = best_model\n",
    "model_save_path = \"model_1.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(model,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxEbFSPN1pHR"
   },
   "source": [
    "<a id='the_logging'></a>\n",
    "## Logging to comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMw5jOIsBfn5"
   },
   "outputs": [],
   "source": [
    "def the_fit(model): \n",
    "   \n",
    "    \n",
    "    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', model)])\n",
    "\n",
    "    # Feed the training data through the pipeline\n",
    "    return text_clf.fit(X_train, y_train) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9DrxIbpBfn8"
   },
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred = the_fit(model1).predict(X_train)   \n",
    "#y_pred = log_comet(model1,X_train).predict(X_train)   \n",
    "y_pred_test = the_fit(model1).predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0orVd1LlBfn-"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_train,y_pred)\n",
    "precision = precision_score(y_train,y_pred,average='weighted')\n",
    "recall = recall_score(y_train,y_pred,average='weighted')\n",
    "f1 = f1_score(y_train,y_pred,average='weighted')\n",
    "f1_test = f1_score(y_test,y_pred_test,average='weighted')\n",
    "    \n",
    "# Create dictionary for metrics\n",
    "performance = {\"accuracy\": accuracy,\"precision\":precision,\n",
    "                   \"recall\":recall,\"f1\":f1,\"f1_test\":f1_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsBp82dK1W4J"
   },
   "outputs": [],
   "source": [
    "#Log parameters and results (saving parameters)\n",
    "\n",
    "#UNCOMMENT\n",
    "#experiment.log_metrics(performance)\n",
    "#experiment.log_conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgjhH4QNBfoB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pwyR9zP4iwc"
   },
   "source": [
    "\n",
    "### Display comet page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYxtgi0e4v0O"
   },
   "outputs": [],
   "source": [
    "# experiment.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyvWvySg48bE"
   },
   "source": [
    "### End experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxuqtHIq47pg"
   },
   "outputs": [],
   "source": [
    "#experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g_jubI05Gko"
   },
   "source": [
    "<a id='the_conclusion'></a>\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAhCGvp29NhV"
   },
   "source": [
    "The purpose of this notebook was to build a classifier to determine whether a person believes if climate change is man-made or not, based on their novel tweet data.\n",
    "\n",
    "Various text preprocessing methods (such as noise removal and object standardisation) were applied to the tweets, so that they could be thrown at any classification model.\n",
    "\n",
    "Exploratory data analysis was done, such as visualising the length of tweets per sentiment class, and the most common words found in each sentiment class.\n",
    "\n",
    "It was found that the data was heavily imbalanced; modelling was done before resampling the data and compared to the modelling done after resampling the data. \n",
    "Modelling done after resampling exhibited the tendency of the models to overfit the resampled data. \n",
    "\n",
    "Hyperparametric tuning was also applied in order to optimize the models. \n",
    "\n",
    "From the various models built, the best model is chosen according to the performance metric. In this case, the best model is the one which exhibits the highest `F1-Score`.\n",
    "\n",
    "Hence, the classifier chosen to predict the sentiment of tweets related to climate change is the **fully optimized Kernel SVM model (before resampling).**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
