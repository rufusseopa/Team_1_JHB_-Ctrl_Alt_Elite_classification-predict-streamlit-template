{"cells":[{"metadata":{"id":"1hE3z_ZXBfho"},"cell_type":"markdown","source":"<hr>\n<h1><center>Climate Change Belief Analysis Competition</center></h1>\n<hr>","execution_count":null},{"metadata":{"id":"d676wR1FBfht"},"cell_type":"markdown","source":"## Table of Contents","execution_count":null},{"metadata":{"id":"rFeEOvg2Bfhw"},"cell_type":"markdown","source":"1. [Introduction](#the_intro)\n\n1. [Data Overview](#the_data)\n \n1. [Connecting to Comet](#the_connection)\n \n1. [Importing the libraries](#the_libraries)\n \n1. [Loading the Datasets](#the_load)\n\n1. [Inspecting the Data](#inspecting)\n \n1. [Text PreProcessing](#the_prep)\n\n1. [Exploratory data analysis](#the_analysis)\n \n1. [Feature to Text (Feature Engineering on text)](#the_features)\n \n1. [Modelling before Resampling](#the_fit)\n\n1. [Modelling before Resampling](#the_balancedfit)\n\n1. [Hyperparameter Tuning](#the_tune)\n\n1. [Evaluate Model](#the_eval)\n \n1. [Saving the model](#the_saving)\n\n1. [Logging to Comet](#the_logging)\n\n1. [Conclusions](#the_conclusion)\n","execution_count":null},{"metadata":{"id":"iod1ktDNBfhz"},"cell_type":"markdown","source":"<a id='the_intro'></a>\n## Introduction","execution_count":null},{"metadata":{"id":"wubGFt3d2Hx9"},"cell_type":"markdown","source":"### Problem Identification","execution_count":null},{"metadata":{"id":"fTMxcC_f2RRO"},"cell_type":"markdown","source":"Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n\n\nProviding an accurate and robust solution to this project gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n","execution_count":null},{"metadata":{"id":"ONUXTMViBfh7"},"cell_type":"markdown","source":"### Problem Statement","execution_count":null},{"metadata":{"id":"sRp6-s4ZBfh9"},"cell_type":"markdown","source":"The purpose of this project is to train a Classification model to predict the sentiment of tweets related to climate change.\n\nThe Machine Learning model chosen will be the one with the highest `Weighted F1-score `(the performance metric used to evaluate the models). \n\nClick [here](https://www.kaggle.com/c/climate-change-belief-analysis/overview) to view the competition page.","execution_count":null},{"metadata":{"id":"mdrM5nXj2jg4"},"cell_type":"markdown","source":"<a id='the_data'></a>\n## Data Overview","execution_count":null},{"metadata":{"id":"Zx7gMxtS4Bam"},"cell_type":"markdown","source":"The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected.\n\nThe training and test datasets provided here is a subset of these 43943 tweets.\n\nThe files to be downloaded are:\n* **Train.csv** - the dataset for training our model.\n* **Test.csv** - the dataset for testing our model .\n\nVariable definitions on the train dataset:\n\n`sentiment`: Sentiment of tweet\n\n`message`: Tweet body\n\n`tweetid`: Twitter unique id\n\nEach tweet is labelled as one of the following sentiment classes:\n\n![image.png](data:image/png;base64,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)","execution_count":null},{"metadata":{"id":"4k0BMQ1z_wgJ"},"cell_type":"markdown","source":"<a id='the_connection'></a>\n## Connecting to Comet","execution_count":null},{"metadata":{"id":"_Bdr6an1_4dL"},"cell_type":"markdown","source":"Comet is a platform that allows data scientists and developers to easily monitor, compare and optimize their machine learning models. \nMore information about Comet can be found [here](https://techcrunch.com/2018/04/05/cometml-wants-to-do-for-machine-learning-what-github-did-for-code/#:~:text=Comet.ml%20allows%20data%20scientists,optimize%20their%20machine%20learning%20models.&text=The%20service%20provides%20you%20with,ML).  \n\nFirstly, `comet_ml` has to be installed.\n","execution_count":null},{"metadata":{"id":"3BD0CcukAerr","trusted":true},"cell_type":"code","source":"!pip install comet_ml","execution_count":null,"outputs":[]},{"metadata":{"id":"WWNcee8656VF","trusted":true},"cell_type":"code","source":"import comet_ml\nfrom comet_ml import Experiment\n\n#Setting up the API KEY\nexperiment = Experiment(api_key= 'p0xSNBixchjaLhMutKMYVuJAq',project_name=\"classification_team_1_jhb\",workspace=\"crtshabangu\")","execution_count":null,"outputs":[]},{"metadata":{"id":"qEj4oDes5bvg"},"cell_type":"markdown","source":"<a id='the_libraries'></a>\n## Importing the libraries","execution_count":null},{"metadata":{"id":"LZrViDk65g4s"},"cell_type":"markdown","source":"Before proceeding with importing the usual libraries, there are some natural language processing libraries that need to be installed: \n\n* `spacy`\n* `wordcloud`\n* `nltk`\n\n","execution_count":null},{"metadata":{"id":"ylfS_Iu95gDn","trusted":true},"cell_type":"code","source":"!pip install spacy\n!pip install wordcloud\n!pip install nltk","execution_count":null,"outputs":[]},{"metadata":{"id":"SAq8xhN212Sp","trusted":true},"cell_type":"code","source":"#standard libraries\nimport numpy as np\nimport pandas as pd\n\n#visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport wordcloud\n\n#modeling libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\nfrom sklearn.utils import resample\n\n#text processing libraries\nimport re\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk import TreebankWordTokenizer, SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer\n#nltk.download('stopwords')\nimport string\n\n#pickling\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{"id":"mOk8Taoe_lHW"},"cell_type":"markdown","source":"<a id='the_load'></a>\n## Loading the Datasets","execution_count":null},{"metadata":{"trusted":true,"id":"v65gGRHwBfjN"},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"id":"JkJkO-XoBGZk","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/climate-change-belief-analysis/train.csv')\ntest_data = pd.read_csv('/kaggle/input/climate-change-belief-analysis/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"lkEpisdUFJgM"},"cell_type":"markdown","source":"<a id='inspecting'></a>\n## Inspecting the Data","execution_count":null},{"metadata":{"id":"2GV2A9wUEs0Q","trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"-M4JX1rtFaij","trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"B8tHBW2bBfjj"},"cell_type":"code","source":"len(train_data), len(test_data)","execution_count":null,"outputs":[]},{"metadata":{"id":"1rKzQkyJBfjp"},"cell_type":"markdown","source":"The training set has 15819 tweets.\n\nThe testing set has 10546 tweets. ","execution_count":null},{"metadata":{"id":"5D7BzlfuK2of"},"cell_type":"markdown","source":"For ease, the `tweetid` column is set to be the index. ","execution_count":null},{"metadata":{"id":"lgcc_N62K9XY","trusted":true},"cell_type":"code","source":"train_data.set_index('tweetid', inplace=True)\ntest_data.set_index('tweetid', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"--UNlN93Bfjv"},"cell_type":"markdown","source":"Checking for missing data:","execution_count":null},{"metadata":{"trusted":true,"id":"E5Z-5KacBfjv"},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"02UP-StrBfjy"},"cell_type":"code","source":"test_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"HEKJfJvoBfj2"},"cell_type":"markdown","source":"Checking for empty strings:","execution_count":null},{"metadata":{"trusted":true,"id":"MGAXCy18Bfj3"},"cell_type":"code","source":"blanks = []  # start with an empty list\n\nfor i,lb,tw in train_data.itertuples():  # iterate over the DataFrame\n    if type(tw)==str:                    # avoid NaN values\n        if tw.isspace():                 # test 'review' for whitespace\n            blanks.append(i)             # add matching index numbers to the list\n        \nprint(len(blanks), 'blanks in train data: ', blanks)   # Checking for empty strings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Q9jWz24eBfj6"},"cell_type":"code","source":"blanks = []  # start with an empty list\n\nfor i, tw in test_data.iterrows():  # iterate over the DataFrame\n    if type(tw)==str:            # avoid NaN values\n        if tw.isspace():         # test 'review' for whitespace\n            blanks.append(i)     # add matching index numbers to the list\n        \nprint(len(blanks), 'blanks in test data: ', blanks)","execution_count":null,"outputs":[]},{"metadata":{"id":"1KlU3DzdBfj_"},"cell_type":"markdown","source":"Th data has no missing values, and no empty tweet strings.","execution_count":null},{"metadata":{"id":"t2vLIzKtEoGY"},"cell_type":"markdown","source":"<a id='the_prep'></a>\n## Text PreProcessing","execution_count":null},{"metadata":{"id":"27Guc5gtGZ5J"},"cell_type":"markdown","source":"In classification, the process of cleaning and standardization of text and making it noise-free is known as **text preprocessing**. This entails of:\n* Noise Removal.\n* Object Standardization.\n* Lexicon Normalization.\n","execution_count":null},{"metadata":{"id":"tu5vOrDZIx3e"},"cell_type":"markdown","source":"### **Noise Removal**","execution_count":null},{"metadata":{"id":"llPiRN8rI2yC"},"cell_type":"markdown","source":"Any piece of information (text) that is not relevant in the data is considered as noise. The following constitutes as noise: stop words, urls, links, social media entities, punctuations or any industry-specific words. Noise is to be removed from our data as it is not required.\n \n**NB**: Part of noise removal in this instance involves **Object Standardization**. Object Standardization involves making sense of, or removing words or phrases which are not present in any standard lexical dictionaries. These pieces are not recognized by search engines and models. Some examples include acronyms, hashtags with attached words, and colloquial slangs.","execution_count":null},{"metadata":{"id":"b1XpyxofFeMe","trusted":true},"cell_type":"code","source":"#Converting every tweet to be lower case\ntrain_data['message'] = train_data['message'].str.lower()\ntest_data['message'] = test_data['message'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"id":"gVjcDHH3BfkI"},"cell_type":"markdown","source":"Here, unexpected artifacts, urls, twitter handles and numbers in the tweets are removed. ","execution_count":null},{"metadata":{"id":"aOEiakXrKHjB","trusted":true},"cell_type":"code","source":"def cleaning(text):\n    \n    \"\"\"\n    Function takes in a text, and returns it cleaned of all noise \n    (such as  unexpected artifacts, urls, twitter handles and numbers).\n    \n    \"\"\"\n    \n    text = re.sub(r'http\\S+', '', text)\n    text = re.sub(r'@[\\w]*','',text)\n    text = re.sub(r'â€¦', '', text)\n    text = re.sub(r'…', '', text)\n    text = re.sub(r'â€™', \"'\", text)\n    text = re.sub(r'â€˜', \"'\", text)\n    text = re.sub(r'\\$q\\$', \"'\", text)\n    text = re.sub(r'&amp;', \"and\", text)\n    text = re.sub('[0-9]+', '', text)\n    \n    words = text.split()  \n    \n    return( \" \".join(words))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"LRm0EM7KSuyR","trusted":true},"cell_type":"code","source":"train_data['message'] = train_data['message'].apply(cleaning)\ntest_data['message'] = test_data['message'].apply(cleaning)","execution_count":null,"outputs":[]},{"metadata":{"id":"r9l7rh_XBfkQ"},"cell_type":"markdown","source":"Python's `string` library is used to remove punctuation.","execution_count":null},{"metadata":{"trusted":true,"id":"dWH5BSGEBfkR"},"cell_type":"code","source":"def remove_punctuation(text):\n    \"\"\"custom function to remove the punctuation\"\"\"\n    return text.translate(str.maketrans('', '', string.punctuation))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"v2u4wND8BfkW"},"cell_type":"code","source":"train_data['message'] = train_data['message'].apply(remove_punctuation)\ntest_data['message'] = test_data['message'].apply(remove_punctuation)","execution_count":null,"outputs":[]},{"metadata":{"id":"gI_q_vwwBfkY"},"cell_type":"markdown","source":"It is noticed that the tweets contain 'rt', implying a retweet.\n\nHence, 'rt', 'rts' and 'retweet' are added as stopwords, and all stopwords are now removed. ","execution_count":null},{"metadata":{"id":"0SUq5nFlgax_","trusted":true},"cell_type":"code","source":"#Remove Stop words\ndef stop(text):\n    \n    \"\"\"\" \n    Function takes in some text, adds the variants of 'retweets'\n    into the stopwords list, and then removes all stopwords.\n    \n    \"\"\"\n    \n    word = text.split()\n    #Remove stop words\n    stop_additional = ['rt','rts', 'retweet']\n    stop_word = set().union(stopwords.words('english'), stop_additional)\n    remove_stop = [w for w in word if w not in stop_word]\n    free_stop = \" \".join(remove_stop)\n    \n    return free_stop \n","execution_count":null,"outputs":[]},{"metadata":{"id":"RKHayjizgm0J","trusted":true},"cell_type":"code","source":"train_data['message'] = train_data['message'].apply(stop)\ntest_data['message'] = test_data['message'].apply(stop)","execution_count":null,"outputs":[]},{"metadata":{"id":"rMofB282VO-I"},"cell_type":"markdown","source":"### Lexicon Normalization ","execution_count":null},{"metadata":{"id":"gC9KduwIXftk"},"cell_type":"markdown","source":"Another type of textual noise to be removed include multiple representations exhibited by a single word.","execution_count":null},{"metadata":{"id":"q7nTxqSoX7QA"},"cell_type":"markdown","source":"The common types of Lexicon Normalization:\n\n\n* **Stemming**:  Stemming is a rudimentary rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s”, etc) from a word.\n* **Lemmatization**: Lemmatization, on the other hand, is an organized, and step-by-step procedure of obtaining the root form of the word, by making use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations).\n\nIn this case, lemmatization is chosen. In lemmatization, words like \"loving\", \"lovely\" and \"loved\" are normalized to their root-word \"love\".\nThis process returns words present in our dictionary; unlike stemming which may return words that may not even exist. \n\n\n","execution_count":null},{"metadata":{"trusted":true,"id":"WOj4Qs56Bfki"},"cell_type":"code","source":"def lemmatizer(text):\n    \n    \"\"\"\" \n    Function takes in some text, and returns the lemmatized text.\n    \n    \"\"\"\n    \n    lemma = WordNetLemmatizer()\n    new_text = \" \".join([lemma.lemmatize(lem) for lem in text.split()])\n    \n    return new_text\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"37yssBh2Bfkl"},"cell_type":"code","source":"train_data['message'] = train_data['message'].apply(lemmatizer)\ntest_data['message'] = test_data['message'].apply(lemmatizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"QqJ0fVViBfkr"},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"8DY7xsf6Bfkv"},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"j78M2NOKYtKk"},"cell_type":"markdown","source":"<a id='the_analysis'></a>\n## Explanatory Data Analysis","execution_count":null},{"metadata":{"id":"PA7R-F4wNAeL"},"cell_type":"markdown","source":"### Distribution of the classes","execution_count":null},{"metadata":{"id":"txMcTtlJygvM","trusted":true},"cell_type":"code","source":"# Separate the classes\nnews = train_data[train_data['sentiment']==2]\npro = train_data[train_data['sentiment']==1]\nneutral = train_data[train_data['sentiment']==0]\nanti = train_data[train_data['sentiment']==-1]","execution_count":null,"outputs":[]},{"metadata":{"id":"3dxDJ4IykHPv","trusted":true},"cell_type":"code","source":"# Get all possible labels\nlabels = train_data['sentiment'].unique()\nheights = [len(pro),len(news),len(neutral),len(anti)]\nplt.bar(labels,heights,color='blue')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.xlabel('sentiments')\nplt.ylabel(\"number of observations\")\nplt.title('Distribution of classes')\nexperiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"qI3rqtr-NwuO"},"cell_type":"markdown","source":"Many of the tweets are from people who believe in man-made climate change. Unresolved class imbalance can lead to the classifier been good at predicting the class(es) with the majority of the data points in the dataset. Whether class imbalance results in poor performance or not is something that needs to be tested. \n\nThe exact percentages of these classes are now inspected using a pie chart.","execution_count":null},{"metadata":{"id":"r_OfwEK4N_LF","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,7))\ntrain_data[\"sentiment\"].value_counts().plot.pie(labels=['Pro', 'News', 'Neutral', 'Anti'], \n                                                autopct='%.1f%%',\n                                                title = 'Pie chart showing percentage of class distribution',\n                                                colors = ['grey','lime','brown','blue'])\nexperiment.log_figure(figure=plt,figure_name='Pie chart showing percentages of class distridution')","execution_count":null,"outputs":[]},{"metadata":{"id":"Nv2eL67jBfk-"},"cell_type":"markdown","source":"More that 50% of the tweets belong to the `pro` class. Recall that the `pro` class represent tweets of people who believe in man-made climate change. This could be an indication that people are finally acknowledging this phenomenon, and more people are becoming aware of it. ","execution_count":null},{"metadata":{"id":"25FQN9Z3Bfk_"},"cell_type":"markdown","source":"### Length of tweets per class","execution_count":null},{"metadata":{"trusted":true,"id":"n-SsTarCBflA"},"cell_type":"code","source":"\nfig, axs = plt.subplots(2, 2, figsize=(11,7))\n\naxs[0, 0].hist(pro.message.str.len(),bins=50,label='pro',color='grey')\naxs[0, 0].set_title('pro')\n\naxs[1, 0].set_title('news')\naxs[1, 0].hist(news.message.str.len(),bins=50,label='news',color='lime')\n\naxs[0, 1].set_title('neutral')\naxs[0, 1].hist(neutral.message.str.len(),bins=50,label='neutral',color='brown')\n\naxs[1, 1].set_title('anti')\naxs[1, 1].hist(anti.message.str.len(),bins=50,label='anti',color='blue')\n\nfor ax in axs.flat:\n    ax.set(xlabel='length of tweets', ylabel='number of tweets')\n\n# Hide x labels and tick labels for top plots and y ticks for right plots.\nfor ax in axs.flat:\n    ax.label_outer()\n\nexperiment.log_figure(figure=plt,figure_name='histograms showing the count of length of tweets')     ","execution_count":null,"outputs":[]},{"metadata":{"id":"jrfW63StBflD"},"cell_type":"markdown","source":"It seems like the length for most tweets lie in the `20-120` range in all classes. ","execution_count":null},{"metadata":{"id":"yLpeVkv7cKi0"},"cell_type":"markdown","source":"### Wordclouds: Visualizing frequently used words in the tweets","execution_count":null},{"metadata":{"id":"GInyxbbLBflE"},"cell_type":"markdown","source":"A **word cloud** is a technique used in visualization to represent text data in such a way that the size of each word in the text indicate its significance or occurrances. Words that are largely displayed have a high frequency in the text.","execution_count":null},{"metadata":{"id":"NnOzLrAOcsXY"},"cell_type":"markdown","source":"#### WordCloud 1: Top 50 Words","execution_count":null},{"metadata":{"id":"kbgi8m-Hb0ME","trusted":true},"cell_type":"code","source":"all_words = ''.join([label for label in train_data['message']])","execution_count":null,"outputs":[]},{"metadata":{"id":"UHtJMi3Ic3tP","trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"bdFqZ9HY-oa9"},"cell_type":"markdown","source":"This visual depicts the 50 most common words in the\n dataset. \n* Words like \"climate change\", \"global warming\" and \"science\" are included.","execution_count":null},{"metadata":{"id":"UbSMx0k_d25V"},"cell_type":"markdown","source":"#### WordCloud2: Top 50 Words in \"Pro\" Tweets","execution_count":null},{"metadata":{"id":"88o1dkVZdp9O","trusted":true},"cell_type":"code","source":"pro_tweets = train_data[train_data['sentiment'] == 1]\nall_words = ''.join([label for label in pro_tweets['message']])","execution_count":null,"outputs":[]},{"metadata":{"id":"NXOV6aAber8u","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words in Pro Tweets')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in Pro Tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"bkhyp0_KBflW"},"cell_type":"markdown","source":"This visual depicts the 50 most common words among `pro` tweets.\n\n* Words like \"change denier\", \"tackle climate\" and \"going die\" are included.","execution_count":null},{"metadata":{"id":"cRUNcxU2e5st"},"cell_type":"markdown","source":"#### WordCloud3: Top 50 Words in \"Anti\" Tweets","execution_count":null},{"metadata":{"id":"qzDdSSodew67","trusted":true},"cell_type":"code","source":"anti_tweets = train_data[train_data['sentiment'] == -1]\nall_words = ''.join([label for label in anti_tweets['message']])","execution_count":null,"outputs":[]},{"metadata":{"id":"-4lhMfAKfE8_","trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words in Anti Tweets')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in Anti Tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"9FuQ3Ds59wo1"},"cell_type":"markdown","source":"This visual depicts the 50 most common words among `anti` tweets.\n\n* Words like \"chinese\", \"man made\" and \"trump\" are included.","execution_count":null},{"metadata":{"id":"TLri0ZLyfOdo"},"cell_type":"markdown","source":"#### WordCloud4: Top 50 Words in \"Neutral\" Tweets","execution_count":null},{"metadata":{"id":"cZcW_avLfI-m","trusted":true},"cell_type":"code","source":"neutral_tweets = train_data[train_data['sentiment'] == 0]\nall_words = ''.join([label for label in neutral_tweets['message']])","execution_count":null,"outputs":[]},{"metadata":{"id":"BwgaW7lxfgrq","trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words in Neutral Tweets')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in Neutral Tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"twUQ1Tu0Bflx"},"cell_type":"markdown","source":"This visual depicts the 50 most common words among `neutral` tweets.\n\nWords like \"warming\", \"global\" and \"club penguin\" are included.","execution_count":null},{"metadata":{"id":"JVQ_X9_hfuci"},"cell_type":"markdown","source":"####  WordCloud5: Top 50 Words in \"News\" Tweets","execution_count":null},{"metadata":{"id":"VmSTvSHvfle9","trusted":true},"cell_type":"code","source":"news_tweets = train_data[train_data['sentiment'] == 2]\nall_words = ''.join([label for label in news_tweets['message']])","execution_count":null,"outputs":[]},{"metadata":{"id":"OmoFdvshf0aV","trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, max_words=50).generate(all_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Top 50 Words in News Tweets')\nexperiment.log_figure(figure=plt,figure_name='Wordcloud for top 50 Words in News Tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"09V4izA9Bfl9"},"cell_type":"markdown","source":"This visual depicts the 50 most common words among `news` tweets.\n\nWords like \"paris agreement\", \"scott pruitt\" and \"carbon dioxide\" are included.","execution_count":null},{"metadata":{"id":"Drgdxz7UY4d0"},"cell_type":"markdown","source":"<a id='the_features'></a>\n## Text to Features (Feature Engineering on text data)","execution_count":null},{"metadata":{"id":"PTa9ldGFZZfD"},"cell_type":"markdown","source":"Feature engineering on text data simply means extracting features from text using the following techniques:\n\n* **Bag of Words** <br>\nThis extracts features from text and counts the frequency of words in a document (the simplest form). \n<br>\n*  **TF-IDF** <br>\nTfidf combines **Term Frequency (TF)** and **Inverse Document Frequency** (IDF). It computes the term frequency-inverse document value for each word. TF is the raw count of a term in a document. IDF is an algorithm that reduces the weight for most common words and add more weight for words that are rare in a document. We compute these two as follows:\n  * TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n  * IDF(t) = log_e(Total number of documents / Number of documents with term t in it) \n  <br>\n\n* **Word2Vec** <br>\nThis is a two layer neutral-net that processes text.\n\n","execution_count":null},{"metadata":{"id":"1acpfNcGBfl_"},"cell_type":"markdown","source":"Firstly, the data has to be split into labels and features. ","execution_count":null},{"metadata":{"id":"feYZCCRoGpPE"},"cell_type":"markdown","source":"### Obtaining X and y","execution_count":null},{"metadata":{"id":"MOxLlwaPGoVT","trusted":true},"cell_type":"code","source":"X = train_data['message']\ny = train_data['sentiment'].values\n","execution_count":null,"outputs":[]},{"metadata":{"id":"lyZ0oz32BfmD"},"cell_type":"markdown","source":"### Split the data into train & test sets","execution_count":null},{"metadata":{"trusted":true,"id":"SXC53bEzBfmF"},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"dbj1_ukAbgBw"},"cell_type":"markdown","source":"### Applying Tfidf","execution_count":null},{"metadata":{"id":"S1Xc7b8Fbl6F"},"cell_type":"markdown","source":"We now apply scikit-learn's `TfidfVectorizer` which does the following to our text data:\n\n*   It counts all the occurrences of the unique words and transforms the tweets to feature vectors\n*   A refinement on top of counting the words is to downscale the weight for words that occur in many tweets (such as \"the\") and are therefore less informative than those that occur only in a few tweets (such as \"climate\").\n*   This is achieved by simply dividing the number of occurrences of each word in the tweets by the total number of words in the tweets.\n","execution_count":null},{"metadata":{"id":"CelvHzU0a_Ov","trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_train_tfidf.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"bljkafltb9E-"},"cell_type":"markdown","source":"Note the shape of `X_train_tfidf`, which indicates the number of features in the feature vector.","execution_count":null},{"metadata":{"id":"OGddBsj_iZm2"},"cell_type":"markdown","source":"<a id='the_fit'></a>\n## Modelling before Resampling\n","execution_count":null},{"metadata":{"id":"Fs7_xj2XjYGs"},"cell_type":"markdown","source":"### Fit Model","execution_count":null},{"metadata":{"id":"_aaVuZbNBfmQ"},"cell_type":"markdown","source":"#### Models to Fit:\n\n1. **Logistic Regression**\n   * Logistic Regression models the probability that `Y`(label) belongs to a certain category (or class). It uses the logistic       function to fit the model using a method called the **maximum likelihood**. It produces an `S-shaped` curve. This model         can be extended to **Multi-class classification**, where we combine multiple logistic models using an approach called           `one-vs-rest`.\n<br>   \n\n\n2. **Support Vector Classifier**\n   * \n<br> \n\n \n3. **K-Nearest Neighbors (KNN)**\n   * KNN is an easy and powerful machine learning algorithm. The algorithm works by assigning the majority class of the N            closest neighbors to the current data point. Hence, no training is required for the algorithm, the only thing we do is          choose `k` (i.e. the number of neighbors to consider) and choose the `Euclidean distance function` to calculate proximity.<br>\n   \n   \n4. **Neural Networks** \n    * ???????????\n\n     \n   ","execution_count":null},{"metadata":{"id":"kqxZkPTbjBH2"},"cell_type":"markdown","source":"Remember that only the training set has been vectorized into a full vocabulary. In order to perform an analysis on the test set, it has to be submitted to the same procedures. Hence, the `Pipeline` class is used. .\n","execution_count":null},{"metadata":{"trusted":true,"id":"PrV9Xy57BfmT"},"cell_type":"code","source":"def fit_evaluate_model(model,X_train, y_train):\n    \n    \"\"\"\" \n    Function takes a model to train as input, and returns the performance\n    of said model (in the form of various metrics). \n    \n    \"\"\"\n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n                         ('clf',model)])\n    \n    # Fit the model to the training set\n    text_clf.fit(X_train, y_train) \n    \n    # Obtain predictions on the validation set\n    y_pred = text_clf.predict(X_train)\n    y_pred_test=text_clf.predict(X_test)\n    \n    # Determining the performance of the model\n    accuracy = accuracy_score(y_train,y_pred)\n    precision = precision_score(y_train,y_pred,average='weighted')\n    recall = recall_score(y_train,y_pred,average='weighted')\n    f1 = f1_score(y_train,y_pred,average='weighted')\n    f1_test = f1_score(y_test,y_pred_test,average='weighted')\n    \n    # Create dictionary for metrics\n    performance = {\"accuracy\": accuracy,\"precision\":precision,\n                   \"recall\":recall,\"f1\":f1,\"f1_test\":f1_test}\n    \n    output = pd.DataFrame([performance])\n\n \n    return output\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"j1RASFGYBfmX"},"cell_type":"markdown","source":"#### Model 1 : Logistic Regression","execution_count":null},{"metadata":{"trusted":true,"id":"C8WToKEIBfmX"},"cell_type":"code","source":"model1 = LogisticRegression(C=8.0,multi_class='ovr',max_iter=10000)\nlogistic_model = fit_evaluate_model(model1,X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"DAEIkcm6Bfmd"},"cell_type":"markdown","source":"#### Model 2: Linear SVM model","execution_count":null},{"metadata":{"trusted":true,"id":"MGcXHvpzBfme"},"cell_type":"code","source":"model2 = LinearSVC()\nlinear_svc = fit_evaluate_model(model2,X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"rjR02EgmBfmi"},"cell_type":"markdown","source":"#### Model 3 : Kernel SVM Model","execution_count":null},{"metadata":{"trusted":true,"id":"iQX4mAU8Bfmj"},"cell_type":"code","source":"model3=SVC(kernel = 'rbf')\nkernel_svc = fit_evaluate_model(model3,X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"dF9jHJrWAdNI"},"cell_type":"markdown","source":"#### Model 4 : Naive Bayes","execution_count":null},{"metadata":{"trusted":true,"id":"7y-dkyYtAdNJ"},"cell_type":"code","source":"fit_evaluate_model(MultinomialNB())","execution_count":null,"outputs":[]},{"metadata":{"id":"rrDDVc1aBfmm"},"cell_type":"markdown","source":"#### Assess accuracy","execution_count":null},{"metadata":{"trusted":true,"id":"L70wP_7lBfmm"},"cell_type":"code","source":"assess = pd.concat([logistic_model,linear_svc,kernel_svc])\nassess.index = ['Logistic Regression','Linear SVM Model','Kernel SVM Model']\nassess","execution_count":null,"outputs":[]},{"metadata":{"id":"K0nmMES3Bfms"},"cell_type":"markdown","source":"Since our data is imbalanced.The accuracy metric we use is the `f1_score`. The imbalance we also see in accuracy being significantly higher than the f1 score across all the models. We need to improve our models performance, we can do this by first **resampling** our data and also **hyperparameter tuning**.","execution_count":null},{"metadata":{"id":"tAn2YTMQixnR"},"cell_type":"markdown","source":"<a id='the_balancedfit'></a>\n## Modelling after Resampling","execution_count":null},{"metadata":{"id":"puqyBU9Qmv2I"},"cell_type":"markdown","source":"### Resampling","execution_count":null},{"metadata":{"id":"nPatdo-zjC_2"},"cell_type":"markdown","source":"As mentioned above, our classes are imbalanced. Lets fix the imbalance in our classes. We do this by `resampling`. Resampling consists of three techniques:\n\n\n*   **Upsampling** minority class - increase the minority class by resampling from observations to match # of observations in majority class.\n*   **Downsampling** - reducing the number of observations in majority to match those of the minority class.\n*   **Synthetic data** - Upsampling + downsampling\n\nThis notebook uses the upsampling and downsampling methods.\n\n","execution_count":null},{"metadata":{"id":"bam_Pf3qj8is"},"cell_type":"markdown","source":"The model performance can possibly be improved by rebalancing our data. Before this is done, let us have a look at the current distribution of our classes again:","execution_count":null},{"metadata":{"trusted":true,"id":"mEShW8cDBfmu"},"cell_type":"code","source":"# Separate the classes\nnews = train_data[train_data['sentiment']==2]\npro = train_data[train_data['sentiment']==1]\nneutral = train_data[train_data['sentiment']==0]\nanti = train_data[train_data['sentiment']==-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"dQo3IpyIBfmw"},"cell_type":"code","source":"# Get all possible labels\nlabels = train_data['sentiment'].unique()\nheights = [len(pro),len(news),len(neutral),len(anti)]\nplt.bar(labels,heights,color='grey')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.ylabel(\"# of observations\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"VizXAR3jkbxC"},"cell_type":"markdown","source":"Now let's apply the resampling techniques :","execution_count":null},{"metadata":{"id":"XTVCnPiukmN0"},"cell_type":"markdown","source":"#### Downsampling the majority class","execution_count":null},{"metadata":{"id":"1kPJGZv0kwXf"},"cell_type":"markdown","source":"Since the `pro` class has so many observations, we can reduce it's size by taking a small random subset of observations to match the size of the `news` class.","execution_count":null},{"metadata":{"id":"U7Jq3zOVkJac","trusted":true},"cell_type":"code","source":"# Downsample majority\npro_downsampled = resample(pro,\n                          replace=False, # sample without replacement (no need to duplicate observations)\n                          n_samples=len(news)) # match number in minority class\n\n# Combine downsampled majority class with minority classes\ndownsampled = pd.concat([pro_downsampled, anti, neutral, news])\n\n# Check new class counts\ndownsampled['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"bac7JA-YlPvY","trusted":true},"cell_type":"code","source":"downsampled_heights = [len(downsampled[downsampled['sentiment']==1]),len(downsampled[downsampled['sentiment']==2]),\n                       len(downsampled[downsampled['sentiment']==0]),len(downsampled[downsampled['sentiment']==-1])]\n\n# Get all possible labels\nlabels = train_data['sentiment'].unique()\nplt.bar(labels,heights,color='grey')\nplt.bar(labels,downsampled_heights,color='blue')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.ylabel(\"number of observations\")\nplt.legend(['original','resampled'])\nexperiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes after downsampling')   \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"MfErKGvklbxq"},"cell_type":"markdown","source":"#### Upsampling the minority class","execution_count":null},{"metadata":{"id":"vWTVOelSlefk"},"cell_type":"markdown","source":" Here, random copies of observations in the `anti` and `neutral` classes are made until we match the size of the `news` class. Using this approach means that there will be more data; however the model will be prone to overfitting. ","execution_count":null},{"metadata":{"id":"36--x0lwk5ch","trusted":true},"cell_type":"code","source":"# Upsample minority\nanti_upsampled = resample(anti,\n                          replace=True, # sample with replacement (we need to duplicate observations)\n                          n_samples=len(news)) # match number in minority class\n\n# Combine upsampled anti class with majority classes\nup_sampled = pd.concat([pro_downsampled, anti_upsampled, neutral, news])\n\n# Check new class counts\nup_sampled['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"SNjbdqmkl1Jh","trusted":true},"cell_type":"code","source":"# Upsample minority\nneutral_upsampled = resample(neutral,\n                          replace=True, # sample with replacement (we need to duplicate observations)\n                          n_samples=len(news)) # match number in minority class\n\n# Combine upsampled neutral class with majority class\nfinal = pd.concat([pro_downsampled, anti_upsampled, neutral_upsampled, news])\n\n# Check new class counts\nfinal['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"-nwzB_fsl7G8","trusted":true},"cell_type":"code","source":"upsampled_heights = [len(final[final['sentiment']==1]),len(final[final['sentiment']==2]),\n                     len(final[final['sentiment']==0]),len(final[final['sentiment']==-1])]\n\n# Get all possible labels\nlabels = train_data['sentiment'].unique()\nplt.bar(labels,upsampled_heights,color='green')\nplt.bar(labels,heights,color='grey')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.ylabel(\"number of observations\")\nplt.legend(['resampled','original'])\nexperiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes after upsampling')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"pEabmov6mFXc"},"cell_type":"markdown","source":"Visualizing the new data:","execution_count":null},{"metadata":{"id":"0QRTplOYl_rv","trusted":true},"cell_type":"code","source":"# Get all possible labels\nlabels = train_data['sentiment'].unique()\nheights = [len(final[final['sentiment']==1]),len(final[final['sentiment']==2]),\n           len(final[final['sentiment']==0]),len(final[final['sentiment']==-1])]\nplt.bar(labels,heights,color='grey')\nplt.xticks(labels,['pro','news', 'neutral', 'anti'])\nplt.ylabel(\"number of observations\")\nexperiment.log_figure(figure=plt,figure_name='Bar plot showing distribution of classes after resampling')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"pT4YrAa5mXm8"},"cell_type":"markdown","source":"These are now evenly distributed observations that can now be thrown at any classification model.","execution_count":null},{"metadata":{"id":"WNgjIFc0AdOH"},"cell_type":"markdown","source":"### Splitting into the training and validation datasets","execution_count":null},{"metadata":{"trusted":true,"id":"NR3HaIWzAdOI"},"cell_type":"code","source":"X = final['message'] \ny = final['sentiment'].values\n\nX_train_resampled, X_test, y_train_resampled, y_test = train_test_split(X,y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"id":"RV5xdUbNm1Vw"},"cell_type":"markdown","source":"### Modelling","execution_count":null},{"metadata":{"trusted":true,"id":"JVl9QlyiBfnH"},"cell_type":"code","source":"#Logistic\nlg = fit_evaluate_model(model1,X_train_resampled,y_train_resampled) \n#Linear SVC model\nl_svc = fit_evaluate_model(model2,X_train_resampled,y_train_resampled)\n#Kernel SVM Model\nk_svc = fit_evaluate_model(model3,X_train_resampled,y_train_resampled)","execution_count":null,"outputs":[]},{"metadata":{"id":"_2I6SHDTBfnM"},"cell_type":"markdown","source":"####  Assess Acurracy on Resampled Data","execution_count":null},{"metadata":{"trusted":true,"id":"Ix9wn9VWBfnM"},"cell_type":"code","source":"assess_resampled = pd.concat([lg,l_svc,k_svc])\nassess_resampled.index = ['Logistic Regression','Linear SVM Model','Kernel SVM Model']\nassess_resampled","execution_count":null,"outputs":[]},{"metadata":{"id":"dCr82XIUBfnO"},"cell_type":"markdown","source":"We see an improvement now that our data is resampled. Lets try hyperparameter tuning on the data to see if we get optimal performance.","execution_count":null},{"metadata":{"id":"3Zy7PEqSEIOY"},"cell_type":"markdown","source":"## Hyperparameter Tuning","execution_count":null},{"metadata":{"id":"7afCx1d8EIOf"},"cell_type":"markdown","source":"A hyperparameter is a value that is set before we train our model. On the contrary, parameters we can only obtain after training the model. Different models have different hyperparameters, they are not the same. In cases where we have simple algorithms such as the K-Nearest Neighbors, we only have one hyperparameter `no.of neighbors`.\n<br>\n\nFirstly, let's look at the hyperparameters of some of the models we will fit : <br>\n\n**Logistic Regression**<br>\n`C`: controls regularization(shrinkage). The smaller value of `C`, the greater the amount of shrinkage that takes place. <br>\n\n**Support Vector Classifier** <br>\n`C`: controls the penalty of the error term.<br>\n`gamma`: kernel coefficient. <br>\nSupport Vector Classifier has tons of hyperparameters but for simplicity purposes we only focus on only these two. \n\n**KNN**<br>\n`k`: number of nearest neighbors. The more neighbors we have the better.<br>\n\n**Neural networks**<br>\n????????????????????","execution_count":null},{"metadata":{"id":"2Z4BH9S6EIOh"},"cell_type":"markdown","source":"**Hyperparameter Tuning/Optimization** is the process of selecting these a combination of hyperparameters that are optimal for our model.\n<br>\n\nThere are many techiniques to tune the hyperparameters, in our case, we will use the `GridSearch`.<br>\n\nA **GridSearch** is an optimization that process that finds the best hyperparameters. It is a trial-and-error method and we train the model of different combinations of hyperparameters.","execution_count":null},{"metadata":{"trusted":true,"id":"TaqMggjYAdNP"},"cell_type":"code","source":"def tuned_model(model, parameters):\n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n                         ('clf',model)]) \n    \n    grid_search = GridSearchCV(estimator = text_clf,\n                               param_grid = parameters,\n                               scoring = 'f1_weighted',\n                               cv = 10,\n                               n_jobs = -1)\n    grid_search = grid_search.fit(X_train, y_train)\n    best_accuracy = grid_search.best_score_\n    best_parameters = grid_search.best_params_\n    print(\"Best f1-score: {:.2f}\".format(best_accuracy))\n    print(\"Best Parameters:\", best_parameters)","execution_count":null,"outputs":[]},{"metadata":{"id":"2S5DsLoVAdNU"},"cell_type":"markdown","source":"#### Model 1: Logistic Regression ","execution_count":null},{"metadata":{"trusted":true,"id":"7hK0Zb6eAdNU"},"cell_type":"code","source":"parameters = [{'clf__C': [0.05], 'clf__penalty': ['l1'], 'clf__solver': ['liblinear'], 'clf__verbose':[1]},\n              {'clf__C': np.linspace(1,10,10)}] \n\ntuned_model(LogisticRegression(max_iter=10000), parameters)","execution_count":null,"outputs":[]},{"metadata":{"id":"e9s4au61AdNZ"},"cell_type":"markdown","source":"#### Model 2: Linear SVC","execution_count":null},{"metadata":{"trusted":true,"id":"1Son55ApAdNa"},"cell_type":"code","source":"parameters = [{'clf__C': np.linspace(1,10,10), 'clf__penalty': ['l1','l2']}]\n\ntuned_model(LinearSVC(), parameters)","execution_count":null,"outputs":[]},{"metadata":{"id":"iUR-bF95AdNd"},"cell_type":"markdown","source":"#### Model 3: Kernel SVM","execution_count":null},{"metadata":{"id":"-Ac7r7SmAdNe"},"cell_type":"markdown","source":"The following line of code took hours to load:\n\n\n\n```\nparameters = [{'clf__C': [1, 10, 100], 'clf__kernel': ['poly', 'rbf'],'clf__gamma': ['scale', 'auto']}] \ntuned_model(SVC(kernel = 'rbf'), parameters)\n```\nAnd the output:\n\n\n```\nBest f1-score: 0.73 \nBest Parameters: {'clf__C': 100, 'clf__gamma': 'scale', 'clf__kernel': 'rbf'}\n```\n\n\n","execution_count":null},{"metadata":{"id":"E_tPBJ4hAdNe"},"cell_type":"markdown","source":"For efficiency, the model is trained manually with the said hyperparameters:","execution_count":null},{"metadata":{"trusted":true,"id":"ZvGCPddEAdNf"},"cell_type":"code","source":"#fit_evaluate_model(SVC(kernel = 'rbf', C=100, gamma='scale'))","execution_count":null,"outputs":[]},{"metadata":{"id":"MgYDMk7_Bfnf"},"cell_type":"markdown","source":"<a id='the_eval'></a>\n## Evaluate Models","execution_count":null},{"metadata":{"trusted":true,"id":"36VtEk-mBfnf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"bePtZxk2Bfnl"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"sR_0inDD1OcM"},"cell_type":"markdown","source":"<a id='the_saving'></a>\n## Save the model","execution_count":null},{"metadata":{"id":"vHAwiWVytMeA","trusted":false},"cell_type":"code","source":"model = text_clf_svm\nmodel_save_path = \"model_1.pkl\"\nwith open(model_save_path,'wb') as file:\n    pickle.dump(model,file)","execution_count":null,"outputs":[]},{"metadata":{"id":"rTVL9Yumoc2m"},"cell_type":"markdown","source":"\n### Submission on Kaggle","execution_count":null},{"metadata":{"trusted":true,"id":"Fz4H-aw8Bfnu"},"cell_type":"code","source":"test_x = test_data['message']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"TNLxuWOhBfnx"},"cell_type":"code","source":"def testing(model,test_x):\n    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n                     ('clf',model)])\n    fit = text_clf.fit(X_train, y_train)  \n    #Prediction\n    predicted = text_clf.predict(test_x)\n    return predicted","execution_count":null,"outputs":[]},{"metadata":{"id":"JlCdTlX_krg2","trusted":true},"cell_type":"code","source":"predict = testing(model1,test_x)\npredictions = pd.DataFrame(predict, columns=['sentiment'], index = test_data.index)\npredictions.reset_index(inplace=True)\n#predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"46ToSWkTojVC","trusted":true},"cell_type":"code","source":"predictions.to_csv('/kaggle/working/basic_logistic.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"PxEbFSPN1pHR"},"cell_type":"markdown","source":"<a id='the_logging'></a>\n## Log parameters to comet","execution_count":null},{"metadata":{"trusted":true,"id":"BMw5jOIsBfn5"},"cell_type":"code","source":"def the_fit(model): \n   \n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n                     ('clf', model)])\n\n    # Feed the training data through the pipeline\n    return text_clf.fit(X_train, y_train) \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"_9DrxIbpBfn8"},"cell_type":"code","source":"#Prediction\ny_pred = the_fit(model1).predict(X_train)   \n#y_pred = log_comet(model1,X_train).predict(X_train)   \ny_pred_test = the_fit(model1).predict(X_test)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"0orVd1LlBfn-"},"cell_type":"code","source":"\n# Accuracy\naccuracy = accuracy_score(y_train,y_pred)\nprecision = precision_score(y_train,y_pred,average='weighted')\nrecall = recall_score(y_train,y_pred,average='weighted')\nf1 = f1_score(y_train,y_pred,average='weighted')\nf1_test = f1_score(y_test,y_pred_test,average='weighted')\n    \n# Create dictionary for metrics\nperformance = {\"accuracy\": accuracy,\"precision\":precision,\n                   \"recall\":recall,\"f1\":f1,\"f1_test\":f1_test}","execution_count":null,"outputs":[]},{"metadata":{"id":"BsBp82dK1W4J","trusted":true},"cell_type":"code","source":"#Log parameters and results (saving parameters)\n\n#UNCOMMENT\nexperiment.log_metrics(performance)\n#experiment.log_conf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"SgjhH4QNBfoB"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"1pwyR9zP4iwc"},"cell_type":"markdown","source":"\n### Display comet page","execution_count":null},{"metadata":{"id":"MYxtgi0e4v0O","trusted":false},"cell_type":"code","source":" experiment.display()","execution_count":null,"outputs":[]},{"metadata":{"id":"GyvWvySg48bE"},"cell_type":"markdown","source":"### End experiment","execution_count":null},{"metadata":{"id":"DxuqtHIq47pg","trusted":false},"cell_type":"code","source":"experiment.end()","execution_count":null,"outputs":[]},{"metadata":{"id":"2g_jubI05Gko"},"cell_type":"markdown","source":"<a id='the_conclusion'></a>\n## Conclusion","execution_count":null},{"metadata":{"id":"VAhCGvp29NhV"},"cell_type":"markdown","source":"Working on conclusion as we are still trying out other models.","execution_count":null},{"metadata":{"id":"EbjcJMwp5I0O","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}